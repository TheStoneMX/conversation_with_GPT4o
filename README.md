GPT-4o is a new model from OpenAI that can take text and images as input and output text. This project showcases its potential in Conversational NLP, particularly in assisting with code writing.

Imagine GPT-4o as a coding companion that understands voice commands and provides real-time feedback on your code, aiming to improve the coding process. This project demonstrates how to create such conversational agents using the new GPT-4o API.

## Capabilities
Multimodal Input Processing: GPT-4o can process text, images, and voice, opening doors to various applications like real-time code analysis based on screen content and voice commands.
Conversational NLP: GPT-4o excels in understanding and responding to natural language, making it perfect for creating interactive coding assistants.

## Limitations
Response Time: The current version of the API can be slow, with noticeable delays in responding to queries.
Note
This project does not aim to replace existing tools like Copilot but rather to explore the exciting possibilities of creating conversational AI agents with the GPT-4o API.
